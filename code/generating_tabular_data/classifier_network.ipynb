{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../code/data/cleaned_pokemon.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "'''\n",
    "type1 and type2 are categories and they overlap\n",
    "and thus the encodings must line up.\n",
    "'''\n",
    "df['type1'] = label_encoder.fit_transform(df['type1'])\n",
    "df['type2'] = label_encoder.fit_transform(df['type2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack</th>\n",
       "      <th>defense</th>\n",
       "      <th>hp</th>\n",
       "      <th>sp_attack</th>\n",
       "      <th>sp_defense</th>\n",
       "      <th>speed</th>\n",
       "      <th>base_total</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>318</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>405</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>80</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>625</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>309</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>405</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attack  defense  hp  sp_attack  sp_defense  speed  base_total  type1  type2\n",
       "0      49       49  45         65          65     45         318      9     13\n",
       "1      62       63  60         80          80     60         405      9     13\n",
       "2     100      123  80        122         120     80         625      9     13\n",
       "3      52       43  39         60          50     65         309      6     18\n",
       "4      64       58  58         80          65     80         405      6     18"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack        int64\n",
       "defense       int64\n",
       "hp            int64\n",
       "sp_attack     int64\n",
       "sp_defense    int64\n",
       "speed         int64\n",
       "base_total    int64\n",
       "type1         int64\n",
       "type2         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datatypes are becoming an issue so lets convert to float 32 for ease of training purposes\n",
    "'''\n",
    "\n",
    "X = torch.tensor(df[['attack', 'defense', 'hp', 'sp_attack', 'sp_defense', 'speed', 'base_total']].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[['type1', 'type2']].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Define the batch size for your DataLoader\n",
    "batch_size = 32  # Adjust this value based on your specific needs\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 2)  # 2 output units for two categories\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - Validation Loss: 617.0262\n",
      "Epoch 1, Loss: 836.8729766845703\n",
      "Epoch [2/1000] - Validation Loss: 215.5016\n",
      "Epoch 2, Loss: 412.2348518371582\n",
      "Epoch [3/1000] - Validation Loss: 164.7538\n",
      "Epoch 3, Loss: 162.99139518737792\n",
      "Epoch [4/1000] - Validation Loss: 154.2097\n",
      "Epoch 4, Loss: 152.1987049102783\n",
      "Epoch [5/1000] - Validation Loss: 150.2054\n",
      "Epoch 5, Loss: 144.42448196411132\n",
      "Epoch [6/1000] - Validation Loss: 146.0616\n",
      "Epoch 6, Loss: 141.0264965057373\n",
      "Epoch [7/1000] - Validation Loss: 141.8393\n",
      "Epoch 7, Loss: 137.1287063598633\n",
      "Epoch [8/1000] - Validation Loss: 137.3720\n",
      "Epoch 8, Loss: 133.36943473815919\n",
      "Epoch [9/1000] - Validation Loss: 132.6318\n",
      "Epoch 9, Loss: 129.54101371765137\n",
      "Epoch [10/1000] - Validation Loss: 127.8958\n",
      "Epoch 10, Loss: 124.46048278808594\n",
      "Epoch [11/1000] - Validation Loss: 122.9370\n",
      "Epoch 11, Loss: 119.68153266906738\n",
      "Epoch [12/1000] - Validation Loss: 118.1330\n",
      "Epoch 12, Loss: 114.90026206970215\n",
      "Epoch [13/1000] - Validation Loss: 112.9648\n",
      "Epoch 13, Loss: 110.63207664489747\n",
      "Epoch [14/1000] - Validation Loss: 108.0758\n",
      "Epoch 14, Loss: 105.29314079284669\n",
      "Epoch [15/1000] - Validation Loss: 102.8404\n",
      "Epoch 15, Loss: 100.80064716339112\n",
      "Epoch [16/1000] - Validation Loss: 97.0548\n",
      "Epoch 16, Loss: 96.74850730895996\n",
      "Epoch [17/1000] - Validation Loss: 91.7246\n",
      "Epoch 17, Loss: 90.85666179656982\n",
      "Epoch [18/1000] - Validation Loss: 86.5362\n",
      "Epoch 18, Loss: 85.76058521270753\n",
      "Epoch [19/1000] - Validation Loss: 81.2735\n",
      "Epoch 19, Loss: 80.77903633117675\n",
      "Epoch [20/1000] - Validation Loss: 76.3218\n",
      "Epoch 20, Loss: 75.80256729125976\n",
      "Epoch [21/1000] - Validation Loss: 71.6278\n",
      "Epoch 21, Loss: 71.0860143661499\n",
      "Epoch [22/1000] - Validation Loss: 67.1897\n",
      "Epoch 22, Loss: 66.88902168273925\n",
      "Epoch [23/1000] - Validation Loss: 62.0719\n",
      "Epoch 23, Loss: 62.58298873901367\n",
      "Epoch [24/1000] - Validation Loss: 57.7665\n",
      "Epoch 24, Loss: 58.14563808441162\n",
      "Epoch [25/1000] - Validation Loss: 55.6794\n",
      "Epoch 25, Loss: 53.82223625183106\n",
      "Epoch [26/1000] - Validation Loss: 50.1543\n",
      "Epoch 26, Loss: 50.63195953369141\n",
      "Epoch [27/1000] - Validation Loss: 45.8960\n",
      "Epoch 27, Loss: 46.7057689666748\n",
      "Epoch [28/1000] - Validation Loss: 42.4760\n",
      "Epoch 28, Loss: 43.12027206420898\n",
      "Epoch [29/1000] - Validation Loss: 39.1978\n",
      "Epoch 29, Loss: 39.88908424377441\n",
      "Epoch [30/1000] - Validation Loss: 36.3474\n",
      "Epoch 30, Loss: 36.89885425567627\n",
      "Epoch [31/1000] - Validation Loss: 33.6195\n",
      "Epoch 31, Loss: 34.13701343536377\n",
      "Epoch [32/1000] - Validation Loss: 31.4917\n",
      "Epoch 32, Loss: 31.757603073120116\n",
      "Epoch [33/1000] - Validation Loss: 29.0117\n",
      "Epoch 33, Loss: 29.533503437042235\n",
      "Epoch [34/1000] - Validation Loss: 28.1542\n",
      "Epoch 34, Loss: 27.251363945007324\n",
      "Epoch [35/1000] - Validation Loss: 25.2520\n",
      "Epoch 35, Loss: 26.021612548828124\n",
      "Epoch [36/1000] - Validation Loss: 23.6364\n",
      "Epoch 36, Loss: 23.90029945373535\n",
      "Epoch [37/1000] - Validation Loss: 22.2374\n",
      "Epoch 37, Loss: 22.559599494934083\n",
      "Epoch [38/1000] - Validation Loss: 20.9381\n",
      "Epoch 38, Loss: 21.16447229385376\n",
      "Epoch [39/1000] - Validation Loss: 20.1630\n",
      "Epoch 39, Loss: 19.81532597541809\n",
      "Epoch [40/1000] - Validation Loss: 18.8749\n",
      "Epoch 40, Loss: 18.849323272705078\n",
      "Epoch [41/1000] - Validation Loss: 18.4191\n",
      "Epoch 41, Loss: 17.92044577598572\n",
      "Epoch [42/1000] - Validation Loss: 17.6207\n",
      "Epoch 42, Loss: 17.485518550872804\n",
      "Epoch [43/1000] - Validation Loss: 17.1224\n",
      "Epoch 43, Loss: 16.83754482269287\n",
      "Epoch [44/1000] - Validation Loss: 17.2521\n",
      "Epoch 44, Loss: 16.385614776611327\n",
      "Epoch [45/1000] - Validation Loss: 16.4279\n",
      "Epoch 45, Loss: 15.992066860198975\n",
      "Epoch [46/1000] - Validation Loss: 16.1954\n",
      "Epoch 46, Loss: 15.7069571018219\n",
      "Epoch [47/1000] - Validation Loss: 15.9330\n",
      "Epoch 47, Loss: 15.55259051322937\n",
      "Epoch [48/1000] - Validation Loss: 15.8455\n",
      "Epoch 48, Loss: 15.425314140319824\n",
      "Epoch [49/1000] - Validation Loss: 15.8379\n",
      "Epoch 49, Loss: 15.361830949783325\n",
      "Epoch [50/1000] - Validation Loss: 16.1077\n",
      "Epoch 50, Loss: 15.385249805450439\n",
      "Epoch [51/1000] - Validation Loss: 16.0714\n",
      "Epoch 51, Loss: 15.682141971588134\n",
      "Epoch [52/1000] - Validation Loss: 15.8700\n",
      "Epoch 52, Loss: 15.317701148986817\n",
      "Epoch [53/1000] - Validation Loss: 15.7589\n",
      "Epoch 53, Loss: 15.418702363967896\n",
      "Epoch [54/1000] - Validation Loss: 15.7077\n",
      "Epoch 54, Loss: 15.294394969940186\n",
      "Epoch [55/1000] - Validation Loss: 15.7686\n",
      "Epoch 55, Loss: 15.333518409729004\n",
      "Epoch [56/1000] - Validation Loss: 15.7008\n",
      "Epoch 56, Loss: 15.29771122932434\n",
      "Epoch [57/1000] - Validation Loss: 15.6997\n",
      "Epoch 57, Loss: 15.290165042877197\n",
      "Epoch [58/1000] - Validation Loss: 15.7295\n",
      "Epoch 58, Loss: 15.333748388290406\n",
      "Epoch [59/1000] - Validation Loss: 15.8710\n",
      "Epoch 59, Loss: 15.495371580123901\n",
      "Epoch [60/1000] - Validation Loss: 15.7089\n",
      "Epoch 60, Loss: 15.632491302490234\n",
      "Epoch [61/1000] - Validation Loss: 15.7606\n",
      "Epoch 61, Loss: 15.693123960494995\n",
      "Epoch [62/1000] - Validation Loss: 15.6941\n",
      "Epoch 62, Loss: 15.323298358917237\n",
      "Epoch [63/1000] - Validation Loss: 15.6929\n",
      "Epoch 63, Loss: 15.286606979370116\n",
      "Epoch [64/1000] - Validation Loss: 15.6906\n",
      "Epoch 64, Loss: 15.365385913848877\n",
      "Epoch [65/1000] - Validation Loss: 15.6968\n",
      "Epoch 65, Loss: 15.31276969909668\n",
      "Epoch [66/1000] - Validation Loss: 15.8568\n",
      "Epoch 66, Loss: 15.296362781524659\n",
      "Epoch [67/1000] - Validation Loss: 15.7502\n",
      "Epoch 67, Loss: 15.336225509643555\n",
      "Epoch [68/1000] - Validation Loss: 16.0483\n",
      "Epoch 68, Loss: 15.285611200332642\n",
      "Epoch [69/1000] - Validation Loss: 15.6971\n",
      "Early stopping after 5 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Sample DataFrame\n",
    "# data = {\n",
    "#     'attack': [80, 70, 90, 60, 75],\n",
    "#     'defense': [70, 80, 65, 75, 85],\n",
    "#     'hp': [60, 75, 80, 70, 65],\n",
    "#     'sp_attack': [100, 90, 110, 95, 105],\n",
    "#     'sp_defense': [80, 85, 75, 90, 70],\n",
    "#     'speed': [70, 65, 80, 85, 95],\n",
    "#     'base_total': [510, 500, 600, 490, 530],\n",
    "#     'type1': ['Water', 'Fire', 'Grass', 'Electric', 'Rock'],\n",
    "#     'type2': ['Ground', 'None', 'Poison', 'Flying', 'None']\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Define your input features and target variables\n",
    "# X = torch.tensor(df[['attack', 'defense', 'hp', 'sp_attack', 'sp_defense', 'speed', 'base_total']].values, dtype=torch.float32)\n",
    "\n",
    "# # For multi-label classification, you can keep the target variables as integers\n",
    "# y = torch.tensor(df[['type1', 'type2']].values, dtype=torch.int64)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# validation sets\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_val_test, y_val, y_val_test = train_test_split(X, y, test_size=0.5, random_state=73)\n",
    "\n",
    "# Define a custom neural network model\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "input_dim = X.shape[1]  # Number of input features\n",
    "output_dim = y.shape[1]  # Number of target variables\n",
    "model = MultiLabelClassifier(input_dim, output_dim)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_loss = float('inf')  # Set to positive infinity initially\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "early_stopping_counter = 0  # Counter for patience\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "    \n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"Early stopping after {patience} epochs without improvement.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# After training, you can evaluate the model on the test data and make predictions.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        # Perform evaluation or make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakehenderson/Documents/code/projects/machine-learning-practice/code/generating_tabular_data/classifier_network.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakehenderson/Documents/code/projects/machine-learning-practice/code/generating_tabular_data/classifier_network.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakehenderson/Documents/code/projects/machine-learning-practice/code/generating_tabular_data/classifier_network.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jakehenderson/Documents/code/projects/machine-learning-practice/code/generating_tabular_data/classifier_network.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39;49m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakehenderson/Documents/code/projects/machine-learning-practice/code/generating_tabular_data/classifier_network.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct \u001b[39m/\u001b[39m total\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakehenderson/Documents/code/projects/machine-learning-practice/code/generating_tabular_data/classifier_network.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "# Assuming you have your trained model and a validation dataset loaded\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set the model to evaluation mode (important to turn off dropout, batch normalization, etc.)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "# have to figure out the datatypes thing\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
